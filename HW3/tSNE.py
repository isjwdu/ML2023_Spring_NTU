import numpy as np
import torch
import os
import torchvision.transforms as transforms
from PIL import Image
from torch.utils.data import DataLoader, Subset, Dataset
from torchvision import models
import torch.nn as nn
from tqdm.auto import tqdm
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from tqdm import tqdm
import matplotlib.cm as cm

device = 'cuda' if torch.cuda.is_available() else 'cpu'

_exp_name = "vgg19_bn"

# tfm
test_tfm = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Model
class VGG19_BN(nn.Module):

    def __init__(self, classes_num):                                
        super(VGG19_BN, self).__init__()
        self.vgg19_bn = models.vgg19_bn(weights=None, progress=True)

    def forward(self, x):
        x = self.vgg19_bn(x)
        return x

# Dataset
"""# Datasets
The data is labelled by the name, so we load images and label while calling '__getitem__'
"""
class FoodDataset(Dataset):

    def __init__(self,path,tfm=test_tfm,files = None):
        super(FoodDataset).__init__()
        self.path = path
        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".jpg")])
        if files != None:
            self.files = files
            
        self.transform = tfm
  
    def __len__(self):
        return len(self.files)
  
    def __getitem__(self,idx):
        fname = self.files[idx]
        im = Image.open(fname)
        im = self.transform(im)
        
        try:
            label = int(fname.split("/")[-1].split("_")[0])
        except:
            label = -1 # test has no label
            
        return im,label

# Load the trained model
model = VGG19_BN(11).to(device)
state_dict = torch.load(f"{_exp_name}_best.ckpt")
model.load_state_dict(state_dict)
model.eval()

print(model)

# Load the vaildation set defined by TA
valid_set = FoodDataset("./valid", tfm=test_tfm)
valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)

# reference: debug and re-generated by GPT
def extract_features(model, layer_index, dataloader):
    features = []
    labels = []

    for batch in tqdm(dataloader):
        imgs, lbls = batch
        with torch.no_grad():
            logits = model.vgg19_bn.features[:layer_index](imgs.to(device))
            logits = logits.view(logits.size()[0], -1)
        labels.extend(lbls.cpu().numpy())
        logits = np.squeeze(logits.cpu().numpy())
        features.extend(logits)

    return np.array(features), np.array(labels)

top_layer_index = 52 # vgg19bn last
mid_layer_index = 36 # vgg19bn penultimate

top_features, top_labels = extract_features(model, top_layer_index, valid_loader)
mid_features, mid_labels = extract_features(model, mid_layer_index, valid_loader)

colors_per_class = cm.rainbow(np.linspace(0, 1, 11))

def plot_tsne(features_tsne, labels, title, save_path):
    plt.figure(figsize=(10, 8))
    for label in np.unique(labels):
        plt.scatter(features_tsne[labels == label, 0], features_tsne[labels == label, 1], label=label, s=5)
    plt.legend()
    plt.title(title)
    plt.xlim(-100, 100)  # set x
    plt.ylim(-100, 100)  # set y
    plt.savefig(save_path)
    plt.show()

top_features_tsne = TSNE(n_components=2, init='pca', random_state=42).fit_transform(top_features)
mid_features_tsne = TSNE(n_components=2, init='pca', random_state=42).fit_transform(mid_features)

plot_tsne(top_features_tsne, top_labels, "t-SNE: Top Layer", "./tSNE_top.jpg")
plot_tsne(mid_features_tsne, mid_labels, "t-SNE: Mid Layer", "./tSNE_mid.jpg")
