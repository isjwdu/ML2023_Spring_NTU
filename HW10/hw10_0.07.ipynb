{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H9m2AbpHC9vS"
   },
   "source": [
    "# **Homework 10 - Adversarial Attack**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k0G8g5KuDBzU"
   },
   "source": [
    "## Enviroment & Download\n",
    "\n",
    "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMK1RhUQCz1e",
    "outputId": "913f8553-9d05-4b33-a551-0fec71ae33f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorchcv in ./.local/lib/python3.10/site-packages (0.0.67)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from pytorchcv) (1.24.3)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from pytorchcv) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests->pytorchcv) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests->pytorchcv) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->pytorchcv) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests->pytorchcv) (2022.12.7)\n",
      "Requirement already satisfied: imgaug in ./.local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: Shapely in ./.local/lib/python3.10/site-packages (from imgaug) (2.0.1)\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.10/site-packages (from imgaug) (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from imgaug) (3.7.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in ./.local/lib/python3.10/site-packages (from imgaug) (0.20.0)\n",
      "Requirement already satisfied: Pillow in ./.local/lib/python3.10/site-packages (from imgaug) (9.5.0)\n",
      "Requirement already satisfied: numpy>=1.15 in ./.local/lib/python3.10/site-packages (from imgaug) (1.24.3)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from imgaug) (1.10.1)\n",
      "Requirement already satisfied: six in ./miniconda3/lib/python3.10/site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: imageio in ./.local/lib/python3.10/site-packages (from imgaug) (2.30.0)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in ./.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.4)\n",
      "/home/u9941117/.local/lib/python3.9/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw\n",
      "To: /home/u9941117/data.zip\n",
      "100%|█████████████████████████████████████████| 490k/490k [00:00<00:00, 200MB/s]\n",
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease                   \n",
      "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Fetched 336 kB in 2s (154 kB/s)  \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-11build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 126 not upgraded.\n",
      "Archive:  ./data.zip\n",
      "   creating: data/\n",
      "   creating: data/deer/\n",
      " extracting: data/deer/deer13.png    \n",
      " extracting: data/deer/deer6.png     \n",
      " extracting: data/deer/deer11.png    \n",
      " extracting: data/deer/deer2.png     \n",
      " extracting: data/deer/deer10.png    \n",
      " extracting: data/deer/deer16.png    \n",
      " extracting: data/deer/deer9.png     \n",
      " extracting: data/deer/deer20.png    \n",
      " extracting: data/deer/deer15.png    \n",
      " extracting: data/deer/deer19.png    \n",
      " extracting: data/deer/deer5.png     \n",
      " extracting: data/deer/deer14.png    \n",
      " extracting: data/deer/deer4.png     \n",
      " extracting: data/deer/deer8.png     \n",
      " extracting: data/deer/deer12.png    \n",
      " extracting: data/deer/deer1.png     \n",
      " extracting: data/deer/deer7.png     \n",
      " extracting: data/deer/deer17.png    \n",
      " extracting: data/deer/deer18.png    \n",
      " extracting: data/deer/deer3.png     \n",
      "   creating: data/horse/\n",
      " extracting: data/horse/horse9.png   \n",
      " extracting: data/horse/horse1.png   \n",
      " extracting: data/horse/horse16.png  \n",
      " extracting: data/horse/horse15.png  \n",
      " extracting: data/horse/horse19.png  \n",
      " extracting: data/horse/horse14.png  \n",
      " extracting: data/horse/horse10.png  \n",
      " extracting: data/horse/horse7.png   \n",
      " extracting: data/horse/horse2.png   \n",
      " extracting: data/horse/horse6.png   \n",
      " extracting: data/horse/horse20.png  \n",
      " extracting: data/horse/horse5.png   \n",
      " extracting: data/horse/horse18.png  \n",
      " extracting: data/horse/horse12.png  \n",
      " extracting: data/horse/horse13.png  \n",
      " extracting: data/horse/horse17.png  \n",
      " extracting: data/horse/horse4.png   \n",
      " extracting: data/horse/horse11.png  \n",
      " extracting: data/horse/horse8.png   \n",
      " extracting: data/horse/horse3.png   \n",
      "   creating: data/ship/\n",
      " extracting: data/ship/ship10.png    \n",
      " extracting: data/ship/ship14.png    \n",
      " extracting: data/ship/ship9.png     \n",
      " extracting: data/ship/ship20.png    \n",
      " extracting: data/ship/ship5.png     \n",
      " extracting: data/ship/ship8.png     \n",
      " extracting: data/ship/ship19.png    \n",
      " extracting: data/ship/ship16.png    \n",
      " extracting: data/ship/ship13.png    \n",
      " extracting: data/ship/ship6.png     \n",
      " extracting: data/ship/ship17.png    \n",
      " extracting: data/ship/ship1.png     \n",
      " extracting: data/ship/ship12.png    \n",
      " extracting: data/ship/ship2.png     \n",
      " extracting: data/ship/ship3.png     \n",
      " extracting: data/ship/ship15.png    \n",
      " extracting: data/ship/ship4.png     \n",
      " extracting: data/ship/ship7.png     \n",
      " extracting: data/ship/ship11.png    \n",
      " extracting: data/ship/ship18.png    \n",
      "   creating: data/frog/\n",
      " extracting: data/frog/frog10.png    \n",
      " extracting: data/frog/frog4.png     \n",
      " extracting: data/frog/frog5.png     \n",
      " extracting: data/frog/frog20.png    \n",
      " extracting: data/frog/frog15.png    \n",
      " extracting: data/frog/frog3.png     \n",
      " extracting: data/frog/frog1.png     \n",
      " extracting: data/frog/frog14.png    \n",
      " extracting: data/frog/frog2.png     \n",
      " extracting: data/frog/frog19.png    \n",
      " extracting: data/frog/frog7.png     \n",
      " extracting: data/frog/frog11.png    \n",
      " extracting: data/frog/frog17.png    \n",
      " extracting: data/frog/frog18.png    \n",
      " extracting: data/frog/frog12.png    \n",
      " extracting: data/frog/frog16.png    \n",
      " extracting: data/frog/frog8.png     \n",
      " extracting: data/frog/frog13.png    \n",
      " extracting: data/frog/frog6.png     \n",
      " extracting: data/frog/frog9.png     \n",
      "   creating: data/airplane/\n",
      " extracting: data/airplane/airplane3.png  \n",
      " extracting: data/airplane/airplane4.png  \n",
      " extracting: data/airplane/airplane2.png  \n",
      " extracting: data/airplane/airplane9.png  \n",
      " extracting: data/airplane/airplane20.png  \n",
      " extracting: data/airplane/airplane18.png  \n",
      " extracting: data/airplane/airplane19.png  \n",
      " extracting: data/airplane/airplane10.png  \n",
      " extracting: data/airplane/airplane6.png  \n",
      " extracting: data/airplane/airplane13.png  \n",
      " extracting: data/airplane/airplane16.png  \n",
      " extracting: data/airplane/airplane14.png  \n",
      " extracting: data/airplane/airplane11.png  \n",
      " extracting: data/airplane/airplane1.png  \n",
      " extracting: data/airplane/airplane17.png  \n",
      " extracting: data/airplane/airplane7.png  \n",
      " extracting: data/airplane/airplane15.png  \n",
      " extracting: data/airplane/airplane5.png  \n",
      " extracting: data/airplane/airplane8.png  \n",
      " extracting: data/airplane/airplane12.png  \n",
      "   creating: data/bird/\n",
      " extracting: data/bird/bird9.png     \n",
      " extracting: data/bird/bird12.png    \n",
      " extracting: data/bird/bird10.png    \n",
      " extracting: data/bird/bird11.png    \n",
      " extracting: data/bird/bird5.png     \n",
      " extracting: data/bird/bird8.png     \n",
      " extracting: data/bird/bird4.png     \n",
      " extracting: data/bird/bird3.png     \n",
      " extracting: data/bird/bird7.png     \r\n",
      " extracting: data/bird/bird18.png    \r\n",
      " extracting: data/bird/bird14.png    \r\n",
      " extracting: data/bird/bird13.png    \r\n",
      " extracting: data/bird/bird2.png     \r\n",
      " extracting: data/bird/bird15.png    \r\n",
      " extracting: data/bird/bird17.png    \r\n",
      " extracting: data/bird/bird19.png    \r\n",
      " extracting: data/bird/bird16.png    \r\n",
      " extracting: data/bird/bird6.png     \r\n",
      " extracting: data/bird/bird20.png    \r\n",
      " extracting: data/bird/bird1.png     \r\n",
      "   creating: data/cat/\r\n",
      " extracting: data/cat/cat6.png       \r\n",
      " extracting: data/cat/cat1.png       \r\n",
      " extracting: data/cat/cat7.png       \r\n",
      " extracting: data/cat/cat19.png      \r\n",
      " extracting: data/cat/cat5.png       \r\n",
      " extracting: data/cat/cat9.png       \r\n",
      " extracting: data/cat/cat17.png      \r\n",
      " extracting: data/cat/cat2.png       \r\n",
      " extracting: data/cat/cat16.png      \r\n",
      " extracting: data/cat/cat10.png      \r\n",
      " extracting: data/cat/cat4.png       \r\n",
      " extracting: data/cat/cat18.png      \r\n",
      " extracting: data/cat/cat13.png      \r\n",
      " extracting: data/cat/cat11.png      \r\n",
      " extracting: data/cat/cat20.png      \r\n",
      " extracting: data/cat/cat15.png      \r\n",
      " extracting: data/cat/cat8.png       \r\n",
      " extracting: data/cat/cat14.png      \r\n",
      " extracting: data/cat/cat3.png       \r\n",
      " extracting: data/cat/cat12.png      \r\n",
      "   creating: data/automobile/\r\n",
      " extracting: data/automobile/automobile17.png  \r\n",
      " extracting: data/automobile/automobile11.png  \r\n",
      " extracting: data/automobile/automobile5.png  \r\n",
      " extracting: data/automobile/automobile10.png  \r\n",
      " extracting: data/automobile/automobile20.png  \r\n",
      " extracting: data/automobile/automobile2.png  \r\n",
      " extracting: data/automobile/automobile6.png  \r\n",
      " extracting: data/automobile/automobile1.png  \r\n",
      " extracting: data/automobile/automobile19.png  \r\n",
      " extracting: data/automobile/automobile7.png  \r\n",
      " extracting: data/automobile/automobile16.png  \r\n",
      " extracting: data/automobile/automobile3.png  \r\n",
      " extracting: data/automobile/automobile14.png  \r\n",
      " extracting: data/automobile/automobile12.png  \r\n",
      " extracting: data/automobile/automobile9.png  \r\n",
      " extracting: data/automobile/automobile4.png  \r\n",
      " extracting: data/automobile/automobile8.png  \r\n",
      " extracting: data/automobile/automobile13.png  \r\n",
      " extracting: data/automobile/automobile18.png  \r\n",
      " extracting: data/automobile/automobile15.png  \r\n",
      "   creating: data/dog/\r\n",
      " extracting: data/dog/dog9.png       \r\n",
      " extracting: data/dog/dog2.png       \r\n",
      " extracting: data/dog/dog15.png      \r\n",
      " extracting: data/dog/dog8.png       \r\n",
      " extracting: data/dog/dog3.png       \r\n",
      " extracting: data/dog/dog19.png      \r\n",
      " extracting: data/dog/dog12.png      \r\n",
      " extracting: data/dog/dog7.png       \r\n",
      " extracting: data/dog/dog17.png      \r\n",
      " extracting: data/dog/dog11.png      \r\n",
      " extracting: data/dog/dog16.png      \r\n",
      " extracting: data/dog/dog20.png      \r\n",
      " extracting: data/dog/dog4.png       \r\n",
      " extracting: data/dog/dog5.png       \r\n",
      " extracting: data/dog/dog14.png      \r\n",
      " extracting: data/dog/dog18.png      \r\n",
      " extracting: data/dog/dog10.png      \r\n",
      " extracting: data/dog/dog1.png       \r\n",
      " extracting: data/dog/dog13.png      \r\n",
      " extracting: data/dog/dog6.png       \r\n",
      "   creating: data/truck/\r\n",
      " extracting: data/truck/truck1.png   \r\n",
      " extracting: data/truck/truck18.png  \r\n",
      " extracting: data/truck/truck9.png   \r\n",
      " extracting: data/truck/truck4.png   \r\n",
      " extracting: data/truck/truck14.png  \r\n",
      " extracting: data/truck/truck8.png   \r\n",
      " extracting: data/truck/truck12.png  \r\n",
      " extracting: data/truck/truck15.png  \r\n",
      " extracting: data/truck/truck2.png   \r\n",
      " extracting: data/truck/truck5.png   \r\n",
      " extracting: data/truck/truck3.png   \r\n",
      " extracting: data/truck/truck10.png  \r\n",
      " extracting: data/truck/truck17.png  \r\n",
      " extracting: data/truck/truck20.png  \r\n",
      " extracting: data/truck/truck19.png  \r\n",
      " extracting: data/truck/truck13.png  \r\n",
      " extracting: data/truck/truck7.png   \r\n",
      " extracting: data/truck/truck6.png   \r\n",
      "  inflating: data/truck/truck16.png  \r\n",
      " extracting: data/truck/truck11.png  \r\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "!pip install pytorchcv\n",
    "!pip install imgaug\n",
    "\n",
    "# download\n",
    "!gdown --id 1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw --output data.zip\n",
    "\n",
    "# if the above link isn't available, try this one\n",
    "# !wget https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\n",
    "\n",
    "# unzip\n",
    "!sudo apt-get update -y\n",
    "!sudo apt-get install zip -y\n",
    "!unzip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-a6naDouEWUZ"
   },
   "outputs": [],
   "source": [
    "!rm ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SaEEx0Y3DMdu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 2\n",
    "\n",
    "def same_seeds(seed):\n",
    "\t  torch.manual_seed(seed)\n",
    "\t  if torch.cuda.is_available():\n",
    "\t\t  torch.cuda.manual_seed(seed)\n",
    "\t\t  torch.cuda.manual_seed_all(seed)\n",
    "\t  np.random.seed(seed)\n",
    "\t  random.seed(seed)\n",
    "\t  torch.backends.cudnn.benchmark = False\n",
    "\t  torch.backends.cudnn.deterministic = True\n",
    "same_seeds(0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8mIr7c0DPsh"
   },
   "source": [
    "## Global Settings \n",
    "#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n",
    "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
    "\n",
    "* Explaination (optional)\n",
    "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
    "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
    "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
    "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IBdYgS2DDNL5"
   },
   "outputs": [],
   "source": [
    "# the mean and std are the calculated statistics from cifar_10 dataset\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "# convert mean and std to 3-dimensional tensors for future operations\n",
    "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
    "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
    "\n",
    "epsilon = 8/255/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AjNkQLoaDWba"
   },
   "outputs": [],
   "source": [
    "root = './data' # directory for storing benign images\n",
    "# benign images: images which do not contain adversarial perturbations\n",
    "# adversarial images: images which include adversarial perturbations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sNf-LoODDZXB"
   },
   "source": [
    "## Data\n",
    "\n",
    "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV7rbnD5DarR",
    "outputId": "6f27c26f-c988-4f65-c694-2aba2a5022e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images = 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
    "])\n",
    "\n",
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        '''\n",
    "        data_dir\n",
    "        ├── class_dir\n",
    "        │   ├── class1.png\n",
    "        │   ├── ...\n",
    "        │   ├── class20.png\n",
    "        '''\n",
    "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
    "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
    "            self.images += images\n",
    "            self.labels += ([i] * len(images))\n",
    "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.images[idx]))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    def __getname__(self):\n",
    "        return self.names\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "adv_set = AdvDataset(root, transform=transform)\n",
    "adv_names = adv_set.__getname__()\n",
    "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'number of images = {adv_set.__len__()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C9D7eakEDflF"
   },
   "source": [
    "## Utils -- Benign Images Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "byE4VH3uDduA"
   },
   "outputs": [],
   "source": [
    "# to evaluate the performance of model on benign images\n",
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yp = model(x)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D3L_qtufDk4j"
   },
   "source": [
    "## Utils -- Attack Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "odTOhtrtDklT"
   },
   "outputs": [],
   "source": [
    "# reference: https://github.com/as791/Adversarial-Example-Attack-and-Defense/blob/master/Adversarial_Example_(Attack_and_defense).ipynb\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# perform fgsm attack\n",
    "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
    "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
    "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "    loss.backward() # calculate gradient\n",
    "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "    grad = x_adv.grad.detach()\n",
    "    x_adv = x_adv + epsilon * grad.sign()\n",
    "    return x_adv\n",
    "\n",
    "# alpha and num_iter can be decided by yourself\n",
    "alpha = 0.8/255/std\n",
    "\n",
    "def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n",
    "    x_adv = x.detach().clone()\n",
    "    ################ TODO: Medium baseline #######################\n",
    "    # write a loop with num_iter times\n",
    "    for i in range(num_iter):\n",
    "      # TODO: Each iteration, execute fgsm\n",
    "      x_adv = x_adv.detach().clone() # initialize x_adv as original benign image x\n",
    "      x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "      loss = loss_fn(model(x_adv), y) # calculate loss\n",
    "      loss.backward() # calculate gradient\n",
    "      # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "      grad = x_adv.grad.detach()\n",
    "      x_adv = x_adv + alpha * grad.sign()\n",
    "      #x_adv = torch.clamp(x_adv, 0, 1)\n",
    "      x_adv = torch.clamp(x_adv, x-epsilon, x+epsilon)\n",
    "\n",
    "    return x_adv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0o9ww4s1DrEx"
   },
   "source": [
    "## Utils -- Attack\n",
    "* Recall\n",
    "  * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "\n",
    "* Inverse function\n",
    "  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
    "  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
    "\n",
    "* Special Noted\n",
    "  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
    "  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rbtfv7rjDrvR"
   },
   "outputs": [],
   "source": [
    "# perform adversarial attack and generate adversarial examples\n",
    "def gen_adv_examples(model, loader, attack, loss_fn):\n",
    "    model.eval()\n",
    "    adv_names = []\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
    "        yp = model(x_adv)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "        # store adversarial examples\n",
    "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
    "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
    "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
    "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
    "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
    "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
    "\n",
    "# create directory which stores adversarial examples\n",
    "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
    "    if os.path.exists(adv_dir) is not True:\n",
    "        _ = shutil.copytree(data_dir, adv_dir)\n",
    "    for example, name in zip(adv_examples, adv_names):\n",
    "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
    "        im.save(os.path.join(adv_dir, name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rbLBR4bjDu7h"
   },
   "source": [
    "## Model / Loss Function\n",
    "\n",
    "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Other kinds of models are prohibited, and it will be considered to be cheating if you use them. \n",
    "\n",
    "Note: Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xCKMshb08I1I"
   },
   "outputs": [],
   "source": [
    "# This function is used to check whether you use models pretrained on cifar10 instead of other datasets\n",
    "def model_checker(model_name):\n",
    "  assert ('cifar10' in model_name) and ('cifar100' not in model_name), 'The model selected is not pretrained on cifar10!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzDUkG0bi2Ts",
    "outputId": "79d860fa-aa09-48fe-db9b-d050e0c5d5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_acc = 0.95000, benign_loss = 0.22678\n"
     ]
    }
   ],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "\n",
    "model_name = 'resnet110_cifar10'\n",
    "model_checker(model_name)\n",
    "\n",
    "model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
    "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCJU4k__DwPT",
    "outputId": "a9ff1c2b-09f7-481e-f181-79b0b8ea972b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u9941117/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_acc = 0.98000, benign_loss = 0.09205\n"
     ]
    }
   ],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "model_names = [\n",
    "    'diaresnet20_cifar10',\n",
    "    'diaresnet56_cifar10',\n",
    "    'diaresnet110_cifar10',\n",
    "    'diaresnet164bn_cifar10',\n",
    "    'diapreresnet20_cifar10',\n",
    "    'diapreresnet56_cifar10',\n",
    "    'diapreresnet110_cifar10',\n",
    "    'diapreresnet164bn_cifar10',\n",
    "    'shakeshakeresnet20_2x16d_cifar10',\n",
    "    'shakeshakeresnet26_2x32d_cifar10',\n",
    "    'pyramidnet110_a48_cifar10',\n",
    "    'pyramidnet110_a84_cifar10', \n",
    "    'pyramidnet110_a270_cifar10', \n",
    "    'pyramidnet164_a270_bn_cifar10', \n",
    "    'pyramidnet200_a240_bn_cifar10', \n",
    "    'pyramidnet236_a220_bn_cifar10', \n",
    "    'pyramidnet272_a200_bn_cifar10', \n",
    "    'densenet40_k12_cifar10',\n",
    "    'densenet40_k12_bc_cifar10', \n",
    "    'densenet40_k24_bc_cifar10', \n",
    "    'densenet40_k36_bc_cifar10', \n",
    "    'densenet100_k12_cifar10',\n",
    "    'densenet100_k24_cifar10', \n",
    "    'densenet100_k12_bc_cifar10', \n",
    "    'densenet190_k40_bc_cifar10', \n",
    "    'densenet250_k24_bc_cifar10', \n",
    "    'xdensenet40_2_k24_bc_cifar10', \n",
    "    'xdensenet40_2_k36_bc_cifar10', \n",
    "    'wrn16_10_cifar10',\n",
    "    'wrn28_10_cifar10',\n",
    "    'wrn40_8_cifar10',\n",
    "    'wrn20_10_1bit_cifar10',\n",
    "    'wrn20_10_32bit_cifar10', \n",
    "    'ror3_56_cifar10',\n",
    "    'ror3_110_cifar10', \n",
    "    'ror3_164_cifar10',\n",
    "    'rir_cifar10',\n",
    "    'resnext29_32x4d_cifar10',\n",
    "    'resnext29_16x64d_cifar10',\n",
    "    'resnext272_1x64d_cifar10',\n",
    "    'resnext272_2x32d_cifar10',\n",
    "    'nin_cifar10',\n",
    "    'resnet20_cifar10',\n",
    "    'resnet56_cifar10',\n",
    "    'resnet110_cifar10',\n",
    "    'resnet164bn_cifar10',\n",
    "    'resnet272bn_cifar10',\n",
    "    'resnet542bn_cifar10',\n",
    "    'resnet1001_cifar10',\n",
    "    'resnet1202_cifar10',\n",
    "    'preresnet20_cifar10',\n",
    "    'preresnet56_cifar10',\n",
    "    'preresnet110_cifar10',\n",
    "    'preresnet164bn_cifar10',\n",
    "    'preresnet272bn_cifar10',\n",
    "    'preresnet542bn_cifar10',\n",
    "    'preresnet1001_cifar10',\n",
    "    'preresnet1202_cifar10',\n",
    "    'seresnet20_cifar10',\n",
    "    'seresnet56_cifar10',\n",
    "    'seresnet110_cifar10',\n",
    "    'seresnet164bn_cifar10',\n",
    "    'seresnet272bn_cifar10',\n",
    "    'seresnet542bn_cifar10', \n",
    "    'sepreresnet20_cifar10', \n",
    "    'sepreresnet56_cifar10', \n",
    "    'sepreresnet110_cifar10', \n",
    "    'sepreresnet164bn_cifar10', \n",
    "    'sepreresnet272bn_cifar10', \n",
    "    'sepreresnet542bn_cifar10', \n",
    "]\n",
    "################ BOSS BASELINE ######################\n",
    "class ensembleNet(nn.Module):\n",
    "    def __init__(self, model_names):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        total_logits = 0\n",
    "        for model in self.models:\n",
    "            model_output = model(x.clone())\n",
    "            total_logits += model_output\n",
    "\n",
    "        averaged_logits = total_logits / len(self.models)\n",
    "        return averaged_logits\n",
    "\n",
    "for model_name in model_names:\n",
    "  model_checker(model_name)\n",
    "\n",
    "ensemble_model = ensembleNet(model_names).to(device)\n",
    "ensemble_model.eval()\n",
    "\n",
    "benign_acc, benign_loss = epoch_benign(ensemble_model, adv_loader, loss_fn)\n",
    "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-CWEsxsUD0Mo"
   },
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP6s-MCODyyh",
    "outputId": "75caabe4-bc7f-4b65-9727-4377e02558d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm_acc = 0.57000, fgsm_loss = 1.96559\n"
     ]
    }
   ],
   "source": [
    "adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(ensemble_model, adv_loader, fgsm, loss_fn)\n",
    "print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n",
    "\n",
    "create_dir(root, 'fgsm', adv_examples, adv_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vXNlkaPWKf8o"
   },
   "source": [
    "# IFGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ppEtuE-op7i",
    "outputId": "0449fc2a-c6d2-4c54-fdaf-dc8f4126921f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifgsm_acc = 0.00500, ifgsm_loss = 13.84004\n"
     ]
    }
   ],
   "source": [
    "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(ensemble_model, adv_loader, ifgsm, loss_fn)\n",
    "print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n",
    "\n",
    "create_dir(root, 'ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lx-X40vrD3S7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9941117/ifgsm\n",
      "airplane/\n",
      "airplane/airplane17.png\n",
      "airplane/airplane7.png\n",
      "airplane/airplane16.png\n",
      "airplane/airplane12.png\n",
      "airplane/airplane13.png\n",
      "airplane/airplane20.png\n",
      "airplane/airplane19.png\n",
      "airplane/airplane5.png\n",
      "airplane/airplane14.png\n",
      "airplane/airplane4.png\n",
      "airplane/airplane15.png\n",
      "airplane/airplane9.png\n",
      "airplane/airplane1.png\n",
      "airplane/airplane6.png\n",
      "airplane/airplane10.png\n",
      "airplane/airplane8.png\n",
      "airplane/airplane11.png\n",
      "airplane/airplane18.png\n",
      "airplane/airplane3.png\n",
      "airplane/airplane2.png\n",
      "automobile/\n",
      "automobile/automobile17.png\n",
      "automobile/automobile12.png\n",
      "automobile/automobile18.png\n",
      "automobile/automobile5.png\n",
      "automobile/automobile9.png\n",
      "automobile/automobile14.png\n",
      "automobile/automobile7.png\n",
      "automobile/automobile20.png\n",
      "automobile/automobile19.png\n",
      "automobile/automobile4.png\n",
      "automobile/automobile13.png\n",
      "automobile/automobile1.png\n",
      "automobile/automobile2.png\n",
      "automobile/automobile6.png\n",
      "automobile/automobile3.png\n",
      "automobile/automobile10.png\n",
      "automobile/automobile8.png\n",
      "automobile/automobile16.png\n",
      "automobile/automobile15.png\n",
      "automobile/automobile11.png\n",
      "bird/\n",
      "bird/bird16.png\n",
      "bird/bird2.png\n",
      "bird/bird6.png\n",
      "bird/bird14.png\n",
      "bird/bird5.png\n",
      "bird/bird9.png\n",
      "bird/bird1.png\n",
      "bird/bird4.png\n",
      "bird/bird7.png\n",
      "bird/bird15.png\n",
      "bird/bird19.png\n",
      "bird/bird10.png\n",
      "bird/bird8.png\n",
      "bird/bird18.png\n",
      "bird/bird13.png\n",
      "bird/bird11.png\n",
      "bird/bird17.png\n",
      "bird/bird12.png\n",
      "bird/bird3.png\n",
      "bird/bird20.png\n",
      "cat/\n",
      "cat/cat10.png\n",
      "cat/cat13.png\n",
      "cat/cat20.png\n",
      "cat/cat19.png\n",
      "cat/cat11.png\n",
      "cat/cat9.png\n",
      "cat/cat15.png\n",
      "cat/cat8.png\n",
      "cat/cat7.png\n",
      "cat/cat18.png\n",
      "cat/cat6.png\n",
      "cat/cat12.png\n",
      "cat/cat16.png\n",
      "cat/cat5.png\n",
      "cat/cat14.png\n",
      "cat/cat4.png\n",
      "cat/cat3.png\n",
      "cat/cat2.png\n",
      "cat/cat1.png\n",
      "cat/cat17.png\n",
      "deer/\n",
      "deer/deer2.png\n",
      "deer/deer13.png\n",
      "deer/deer6.png\n",
      "deer/deer18.png\n",
      "deer/deer9.png\n",
      "deer/deer4.png\n",
      "deer/deer7.png\n",
      "deer/deer14.png\n",
      "deer/deer10.png\n",
      "deer/deer11.png\n",
      "deer/deer8.png\n",
      "deer/deer12.png\n",
      "deer/deer19.png\n",
      "deer/deer20.png\n",
      "deer/deer3.png\n",
      "deer/deer15.png\n",
      "deer/deer1.png\n",
      "deer/deer17.png\n",
      "deer/deer5.png\n",
      "deer/deer16.png\n",
      "dog/\n",
      "dog/dog13.png\n",
      "dog/dog20.png\n",
      "dog/dog10.png\n",
      "dog/dog16.png\n",
      "dog/dog9.png\n",
      "dog/dog8.png\n",
      "dog/dog12.png\n",
      "dog/dog15.png\n",
      "dog/dog7.png\n",
      "dog/dog19.png\n",
      "dog/dog6.png\n",
      "dog/dog5.png\n",
      "dog/dog18.png\n",
      "dog/dog4.png\n",
      "dog/dog3.png\n",
      "dog/dog14.png\n",
      "dog/dog17.png\n",
      "dog/dog2.png\n",
      "dog/dog1.png\n",
      "dog/dog11.png\n",
      "frog/\n",
      "frog/frog8.png\n",
      "frog/frog4.png\n",
      "frog/frog3.png\n",
      "frog/frog12.png\n",
      "frog/frog6.png\n",
      "frog/frog10.png\n",
      "frog/frog13.png\n",
      "frog/frog18.png\n",
      "frog/frog16.png\n",
      "frog/frog7.png\n",
      "frog/frog5.png\n",
      "frog/frog1.png\n",
      "frog/frog20.png\n",
      "frog/frog2.png\n",
      "frog/frog9.png\n",
      "frog/frog15.png\n",
      "frog/frog14.png\n",
      "frog/frog17.png\n",
      "frog/frog19.png\n",
      "frog/frog11.png\n",
      "horse/\n",
      "horse/horse1.png\n",
      "horse/horse13.png\n",
      "horse/horse7.png\n",
      "horse/horse5.png\n",
      "horse/horse9.png\n",
      "horse/horse20.png\n",
      "horse/horse2.png\n",
      "horse/horse15.png\n",
      "horse/horse3.png\n",
      "horse/horse6.png\n",
      "horse/horse17.png\n",
      "horse/horse18.png\n",
      "horse/horse11.png\n",
      "horse/horse16.png\n",
      "horse/horse14.png\n",
      "horse/horse10.png\n",
      "horse/horse19.png\n",
      "horse/horse12.png\n",
      "horse/horse8.png\n",
      "horse/horse4.png\n",
      "ship/\n",
      "ship/ship12.png\n",
      "ship/ship16.png\n",
      "ship/ship11.png\n",
      "ship/ship20.png\n",
      "ship/ship18.png\n",
      "ship/ship13.png\n",
      "ship/ship10.png\n",
      "ship/ship8.png\n",
      "ship/ship5.png\n",
      "ship/ship4.png\n",
      "ship/ship2.png\n",
      "ship/ship3.png\n",
      "ship/ship15.png\n",
      "ship/ship19.png\n",
      "ship/ship6.png\n",
      "ship/ship14.png\n",
      "ship/ship9.png\n",
      "ship/ship7.png\n",
      "ship/ship17.png\n",
      "ship/ship1.png\n",
      "truck/\n",
      "truck/truck1.png\n",
      "truck/truck18.png\n",
      "truck/truck7.png\n",
      "truck/truck11.png\n",
      "truck/truck9.png\n",
      "truck/truck8.png\n",
      "truck/truck5.png\n",
      "truck/truck10.png\n",
      "truck/truck6.png\n",
      "truck/truck3.png\n",
      "truck/truck14.png\n",
      "truck/truck13.png\n",
      "truck/truck20.png\n",
      "truck/truck17.png\n",
      "truck/truck2.png\n",
      "truck/truck19.png\n",
      "truck/truck12.png\n",
      "truck/truck15.png\n",
      "truck/truck4.png\n",
      "truck/truck16.png\n",
      "/home/u9941117\n"
     ]
    }
   ],
   "source": [
    "%cd ifgsm\n",
    "!tar zcvf ../ifgsm.tgz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "--9YWbhn_Evr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from google.colab import files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfiles\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mifgsm.tgz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "#from google.colab import files\n",
    "files.download('ifgsm.tgz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4N6Me0GQECfZ"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxNrXHKsEDGx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "cnt = 0\n",
    "for i, cls_name in enumerate(classes):\n",
    "    path = f'{cls_name}/{cls_name}1.png'\n",
    "    # benign image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./data/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "    # adversarial image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./fgsm/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WDc6QllJEHiC"
   },
   "source": [
    "## Report Question\n",
    "* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhFVWA6JEH8Z"
   },
   "outputs": [],
   "source": [
    "# original image\n",
    "path = f'dog/dog2.png'\n",
    "im = Image.open(f'./data/{path}')\n",
    "logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "predict = logit.argmax(-1).item()\n",
    "prob = logit.softmax(-1)[predict].item()\n",
    "plt.title(f'benign: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "plt.axis('off')\n",
    "plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# adversarial image \n",
    "adv_im = Image.open(f'./fgsm/{path}')\n",
    "logit = model(transform(adv_im).unsqueeze(0).to(device))[0]\n",
    "predict = logit.argmax(-1).item()\n",
    "prob = logit.softmax(-1)[predict].item()\n",
    "plt.title(f'adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "plt.axis('off')\n",
    "plt.imshow(np.array(adv_im))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NfwhnywXEMwZ"
   },
   "source": [
    "## Passive Defense - JPEG compression\n",
    "JPEG compression by imgaug package, compression rate set to 70\n",
    "\n",
    "Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression\n",
    "\n",
    "Note: If you haven't implemented the JPEG compression, this module will return an error. Don't worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2T7-L-BEKYg"
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# pre-process image\n",
    "x = transforms.ToTensor()(adv_im)*255\n",
    "x = x.permute(1, 2, 0).numpy()\n",
    "x = x.astype(np.uint8)\n",
    "\n",
    "# TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n",
    "# compressed_x =  ... x .. \n",
    "# Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression\n",
    "aug = iaa.JpegCompression(compression=(70,70))\n",
    "compressed_x = aug(images=x)\n",
    "\n",
    "logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n",
    "predict = logit.argmax(-1).item()\n",
    "prob = logit.softmax(-1)[predict].item()\n",
    "plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.imshow(compressed_x)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
